{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7-final"},"orig_nbformat":2,"kernelspec":{"name":"python37764bitprojectopencvconda6fc4edbc446e42ca82ff567e09c1586a","display_name":"Python 3.7.7 64-bit ('project_opencv': conda)"},"colab":{"name":"CNN_DB_predict_0520.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"6oUqyZkiw6uo","colab_type":"code","colab":{}},"source":["# groups_folder_path = '/content/drive/My Drive/beans'\n","# categories = [\"broken\", \"insect\", \"normal\"] # 해당 이미지들이 들어가 있는 폴더명 넣어주기 \n","# num_classes = len(categories)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqOjAOJKw6ur","colab_type":"code","outputId":"59648016-98bd-4e54-db5b-46af05af3037","colab":{}},"source":["#pip install sklearn"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Collecting scikit-learn\n","  Downloading scikit_learn-0.23.0-cp37-cp37m-win_amd64.whl (6.8 MB)\n","Collecting joblib>=0.11\n","  Downloading joblib-0.15.1-py3-none-any.whl (298 kB)\n","Requirement already satisfied: scipy>=0.19.1 in c:\\users\\admin\\anaconda3\\envs\\project_opencv\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in c:\\users\\admin\\anaconda3\\envs\\project_opencv\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-2.0.0-py3-none-any.whl (34 kB)\n","Building wheels for collected packages: sklearn\n","  Building wheel for sklearn (setup.py): started\n","  Building wheel for sklearn (setup.py): finished with status 'done'\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1320 sha256=039a5a6d34665b365cd6d63473fee7a168aa3d9d3535ec647a162543acf0dc02\n","  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\46\\ef\\c3\\157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","Successfully built sklearn\n","Installing collected packages: joblib, threadpoolctl, scikit-learn, sklearn\n","Successfully installed joblib-0.15.1 scikit-learn-0.23.0 sklearn-0.0 threadpoolctl-2.0.0\n","Note: you may need to restart the kernel to use updated packages.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NSA96Fghw6uu","colab_type":"code","colab":{}},"source":["import torch\n","from torch.autograd import Variable \n","import torch.nn as nn \n","import torch.nn.functional as F \n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import os \n","from PIL import Image \n","import numpy as np\n","import pandas as pd\n","from sklearn import datasets, model_selection"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzLeiZADw6ux","colab_type":"code","colab":{}},"source":["import pymongo\n","import gridfs \n","from pymongo import MongoClient"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nKmr6xTSw6uz","colab_type":"code","colab":{}},"source":["groups_folder_path = './beans'\n","categories = [\"broken\", \"normal\"] # 해당 이미지들이 들어가 있는 폴더명 넣어주기 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbR2W38vw6u1","colab_type":"code","colab":{}},"source":["# # mongodb에서 사진 불러오기 \n","# # category 나눠서 들어갈 수 있도록 하기 \n","\n","\n","\n","# if __name__ == '__main__' :\n","    \n","#     # connect to database \n","#     client = MongoClient('127.0.0.1', 27017)\n","\n","    \n","\n","\n","#     # read in the image \n","\n","#     for i,d in enumerate(categories):\n","#         files = os.listdir(groups_folder_path + '/'+ d)\n","#         database = client[d]\n","\n","#         # create a new gridfs object\n","#         fs = gridfs.GridFS(database)\n","\n","#         for f in files : \n","#             img = open(groups_folder_path + '/'+ d +'/' + f, 'rb')\n","#             thedata = img.read()\n","#             # store the data in the database. \n","#             # Returns the id of the file in gridFS \n","#             stored = fs.put(thedata, filename = f)\n","\n","    \n","    \n","    \n","\n","\n","\n","#     # retrieve what was just stored \n","#     #outputdata = fs.get(stored).read()\n","\n","#     # create an output file and store the image in the output file \n","#     # outfilename = './OpenCV/data/20200508_test1_sample1.jpg'\n","#     # output = open(outfilename, 'wb')\n","#     # output.write(outputdata)\n","#     # # close the output file \n","#     # output.close()\n","\n","#     # for experimental code restore to known state and close connection \n","\n","#     #fs.delete(stored)\n","#     #client.drop_database('example')\n","#     client.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRCZ-QVmw6u3","colab_type":"code","outputId":"7773977f-b4b4-4f12-97df-b3842277842a","colab":{}},"source":["# pip install StringIO"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n","ERROR: Could not find a version that satisfies the requirement StringIO (from versions: none)\n","ERROR: No matching distribution found for StringIO\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NY8AYJ65w6u6","colab_type":"code","colab":{}},"source":["# import base64\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3brEKeNNw6u8","colab_type":"code","outputId":"71f80f88-1fdd-4f3b-f129-e6783db7a421","colab":{}},"source":["# img = Image.open(\"./normal_data/normal_align_test_image/20200518_test_inadvance1_off.jpeg\")\n","# img.size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2160, 2160)"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"zlqYXx-Bw6u-","colab_type":"code","colab":{}},"source":["import io"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":["outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend"],"id":"e-l4TWaZw6vA","colab_type":"code","outputId":"15f7ed75-3390-4e6f-eb0a-277b6a2835c2","colab":{}},"source":["data = []\n","label = []\n","\n","# groups_folder_path = './normal_data'\n","# categories = [\"normal_align_test_image\", \"normal_processed_data\", \"normal_raw_data\" ] # 해당 이미지들이 들어가 있는 폴더명 넣어주기 \n","\n","if __name__ == '__main__' :  \n","  client = MongoClient('127.0.0.1', 27017)\n","  # read in the image \n","  for i,d in enumerate(categories):\n","    database  = client[d]\n","    files     = os.listdir(groups_folder_path + '/'+ d)\n","    \n","    # create a new gridfs object\n","    fs        = gridfs.GridFS(database)\n","\n","    #print( '->' +  d )\n","    for f in files : \n","      #print( groups_folder_path + '/'+ d +'/' + f )\n","      fp         = open(groups_folder_path + '/'+ d +'/' + f, 'rb')\n","      # bytes로 읽는다\n","      thedata     = fp.read()            \n","      \n","      image = Image.open(io.BytesIO(thedata))\n","      #image.show()\n","      \n","      \n","      \n","      #print( type(thedata), len(thedata) )\n","      # 디비에 저장\n","      stored      = fs.put(thedata, filename = f)      \n","      # 디비에서 다시 읽는다\n","      outputdata  = fs.get(stored).read()\n","      #print( type(outputdata), len(outputdata) )\n","      #print( '-'*10 )\n","      \n","      thedata2 = Image.open(fp, mode='r')\n","      \n","\n","      #thedata2 = Image.frombytes('RGB', (2160,2160), outputdata, 'raw')      \n","      # #thedata = Image.open(StringIO.StringIO(outputdata))\n","      # # 이미지 흑백으로 변경 \n","      img = thedata2.convert('L')\n","      # # 이미지를 28, 28로 일괄 리사이즈 \n","      resize_img = img.resize((28,28))\n","      black_resize_img = np.asarray(resize_img)\n","      # # 가공한 이미지 추가 \n","      data.append(black_resize_img)\n","      # # label : broken, insect, normal\n","      label.append(i)\n","\n","      fp.close()\n","      #break\n","\n","\n","  client.close()\n","\n","pd.DataFrame(data[0][0]).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 1)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"Hq5qfwDcw6vC","colab_type":"code","colab":{}},"source":["data = np.array(data, dtype = 'float32')\n","label = np.array(label, dtype = 'int64')\n","\n","train_X, test_X, train_Y, test_Y = model_selection.train_test_split(data, label, test_size = 0.1)\n","\n","train_X = torch.from_numpy(train_X).float()\n","train_Y = torch.from_numpy(train_Y).long()\n","\n","test_X = torch.from_numpy(test_X).float()\n","test_Y = torch.from_numpy(test_Y).long()\n","\n","#train = TensorDataset(train_X, train_Y)\n","#train_loader = DataLoader(train, batch_size = 32, shuffle = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hK5rG3ziw6vF","colab_type":"code","outputId":"0262f190-bbdb-4291-de27-7cf017d22294","colab":{}},"source":["train_X"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n","\n","        [[ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 0.,  0.,  0.,  ...,  0.,  1.,  1.],\n","         [ 0.,  0.,  0.,  ...,  1.,  1.,  1.],\n","         [ 0.,  0.,  0.,  ...,  1.,  1.,  1.]],\n","\n","        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n","\n","        ...,\n","\n","        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 2.,  0., 40.,  ...,  0.,  0.,  0.],\n","         [ 2.,  2., 19.,  ...,  0.,  0.,  0.],\n","         [ 2.,  2.,  5.,  ...,  0.,  0.,  0.]]])"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"KCUj5-xnw6vH","colab_type":"code","outputId":"2cef3e60-586d-46b3-9c8c-cea9642af53a","colab":{}},"source":["train_Y"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 1,  ..., 1, 0, 0])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"RShzWv5Yw6vJ","colab_type":"code","outputId":"90b85ea4-d85b-4a6a-cc74-84c41d29d6f0","colab":{}},"source":["test_X"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        ...,\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]])"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"LadwJLB0w6vL","colab_type":"code","outputId":"f1ff04be-0936-423e-c5c0-6a25ca4f8eba","colab":{}},"source":["test_Y"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n","        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n","        1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n","        0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n","        0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n","        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n","        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n","        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n","        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n","        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n","        1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n","        0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n","        0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n","        0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"kWBYgieuw6vN","colab_type":"code","outputId":"087c6e2c-b8ef-44d5-93e8-a9173162300b","colab":{}},"source":["train_X.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3049, 28, 28])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"OVTNoqvsw6vQ","colab_type":"code","outputId":"858d4d25-1a36-414e-f5c6-b6df47018073","colab":{}},"source":["train_Y.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3049])"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"VWLF-aGBw6vT","colab_type":"code","outputId":"d36caec5-0db9-4285-a8f3-101d6cd2e72b","colab":{}},"source":["test_X.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([339, 28, 28])"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"Hms5O2p3w6vU","colab_type":"code","outputId":"4a9118ea-ede1-448c-c869-085411e624dc","colab":{}},"source":["test_Y.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([339])"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"e8UnW62Vw6vW","colab_type":"code","colab":{}},"source":["# 데이터 차원 맞추기\n","train_X = train_X.unsqueeze(1)\n","test_X = test_X.unsqueeze(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjQc7HcHw6vY","colab_type":"code","outputId":"d298895a-069d-4b55-91de-105b20dd83dc","colab":{}},"source":["train_X.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3049, 1, 28, 28])"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"sSkDpkI7w6va","colab_type":"code","outputId":"0b6c38e2-0753-4631-ec60-9713a258b729","colab":{}},"source":["test_X.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([339, 1, 28, 28])"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"403Z8CTYw6vb","colab_type":"code","colab":{}},"source":["# 만약 GPU를 사용 가능하다면 device 값이 cuda가 되고, 아니라면 cpu가 됩니다.\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# 랜덤 시드 고정\n","torch.manual_seed(777)\n","\n","# GPU 사용 가능일 경우 랜덤 시드 고정\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nf3vm7Bkw6vd","colab_type":"code","outputId":"abe072fc-2b57-4182-c9b1-9399a1068d8d","colab":{}},"source":["dataset = TensorDataset(train_X, train_Y)\n","type(dataset)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.utils.data.dataset.TensorDataset"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"NqdJNUlQw6vg","colab_type":"code","colab":{}},"source":["learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 100\n","\n","data_loader = torch.utils.data.DataLoader(dataset=dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=True,\n","                                          drop_last=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIpCapxYw6vi","colab_type":"code","colab":{}},"source":["class CNN(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        # 첫번째층\n","        # ImgIn shape=(?, 28, 28, 1)\n","        #    Conv     -> (?, 28, 28, 32)\n","        #    Pool     -> (?, 14, 14, 32)\n","        self.layer1 = torch.nn.Sequential(\n","            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1 ),\n","            torch.nn.Tanh(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # 두번째층\n","        # ImgIn shape=(?, 14, 14, 32)\n","        #    Conv      ->(?, 14, 14, 64)\n","        #    Pool      ->(?, 7, 7, 64)\n","        self.layer2 = torch.nn.Sequential(\n","            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            torch.nn.Tanh(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # 전결합층 7x7x64 inputs -> 10 outputs\n","        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n","\n","        # 전결합층 한정으로 가중치 초기화\n","        torch.nn.init.xavier_uniform_(self.fc.weight)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n","        out = self.fc(out)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1robEH0w6vk","colab_type":"code","outputId":"0e665d24-609c-43ed-c032-7b970a98e652","colab":{}},"source":["# 모델을 정의합니다.\n","\n","# CNN 모델 정의\n","model = CNN().to(device)\n","# 비용 함수와 옵티마이저를 정의합니다.\n","\n","criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","# 총 배치의 수를 출력해보겠습니다.\n","\n","total_batch = len(data_loader)\n","print('총 배치의 수 : {}'.format(total_batch))\n","# 총 배치의 수 : 600\n","# 총 배치의 수는 600입니다. 그런데 배치 크기를 100으로 했으므로 결국 훈련 데이터는 총 60,000개란 의미입니다. 이제 모델을 훈련시켜보겠습니다. (시간이 꽤 오래 걸립니다.)\n","\n","model.train()\n","\n","for epoch in range(training_epochs):\n","    \n","    avg_cost = 0\n","    \n","    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n","        # image is already size of (28x28), no reshape\n","        # label is not one-hot encoded\n","        X = X.to(device)\n","        Y = Y.to(device)\n","\n","        optimizer.zero_grad()\n","        hypothesis = model(X)\n","        cost = criterion(hypothesis, Y)\n","        cost.backward()\n","        optimizer.step()\n","\n","        avg_cost += cost / total_batch\n","\n","    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["총 배치의 수 : 30\n","[Epoch:    1] cost = 0.765278161\n","[Epoch:    2] cost = 0.442649037\n","[Epoch:    3] cost = 0.395151377\n","[Epoch:    4] cost = 0.318069965\n","[Epoch:    5] cost = 0.262874067\n","[Epoch:    6] cost = 0.242202535\n","[Epoch:    7] cost = 0.221639827\n","[Epoch:    8] cost = 0.191194206\n","[Epoch:    9] cost = 0.200454101\n","[Epoch:   10] cost = 0.165197507\n","[Epoch:   11] cost = 0.151029497\n","[Epoch:   12] cost = 0.140694171\n","[Epoch:   13] cost = 0.124648988\n","[Epoch:   14] cost = 0.127507478\n","[Epoch:   15] cost = 0.127358168\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yzDX5itaw6vm","colab_type":"code","outputId":"f78c92a4-416a-4756-b71a-5ef5ca7c0b10","colab":{}},"source":["# test dataset 만들기 \n","testset = TensorDataset(test_X, test_Y)\n","type(testset)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.utils.data.dataset.TensorDataset"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"xwD5vVVjw6vn","colab_type":"code","colab":{}},"source":["batch_size = 100\n","\n","testloader = torch.utils.data.DataLoader(dataset=testset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          drop_last=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hy95tKYPw6vp","colab_type":"code","outputId":"6c8ad7cf-bcd4-4b9a-a338-9057bf6f6070","colab":{}},"source":["# 테스트 데이터로 모델 테스트 진행 \n","\"\"\"\n","https://wingnim.tistory.com/36\n","\"\"\"\n","\n","model.eval()\n","test_loss = 0 \n","correct = 0\n","\n","for data, target in testloader: \n","    data = data.to(device)\n","    target = target.to(device) \n","\n","    output = model(data)\n","\n","    # sum up batch loss \n","    test_loss += criterion(output, target).data\n","\n","    # get the index of the max log-probability \n","    pred = output.data.max(1, keepdim = True)[1]\n","    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","\n","test_loss /= len(testloader.dataset)/batch_size\n","\n","print('\\nTest set : Average loss : {: .4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Test set : Average loss :  0.2013, Accuracy: 271/339 (80%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RHciTth6w6vr","colab_type":"code","colab":{}},"source":["\"\"\"\n","https://medium.com/@trilliwon/pytorch-%E1%84%8B%E1%85%B5%E1%84%86%E1%85%B5%E1%84%8C%E1%85%B5-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2-%E1%84%92%E1%85%A2%E1%84%87%E1%85%A9%E1%84%80%E1%85%B5-4ceab523cb66\n","\"\"\"\n","\n","# # 테스트 데이터로 테스트 진행 \n","\n","# categories = [\"broken\", \"normal\"]\n","\n","# class_correct = list(0. for i in range(2))\n","# class_total = list(0. for i in range(2))\n","\n","# with torch.no_grad():\n","#     for data in testloader:\n","#         images, labels = data \n","#         outputs = net(images)\n","#         _, predicted = torch.max(outputs, 1) \n","#         c = (predicted == labels).squeeze()\n","#         for i in range(4):\n","#              label = labels[i]\n","#              class_correct[label] += c[i].item()\n","#              class_total[label] += 1\n","# for i in range(10):\n","#     print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i]/class_total[i]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TXCrjdXCw6vt","colab_type":"code","outputId":"529618e9-3e9d-4e64-8552-2450152d4a48","colab":{}},"source":["# CNN 모델에 이미지 대입하여 예측결과 확인하기 \n","# 참고 사이트 \n","\n","\"\"\"\n","https://github.com/MLlounge/ML-Project/blob/master/Basic%20Project/CNN%20-%20Distinguish%20language%20according%20to%20characters/CNN%20-%20Distinguish%20language%20according%20to%20characters.py\n","\"\"\"\n","\n","\"\"\"\n","https://www.yceffort.kr/2019/01/30/pytorch-3-convolutional-neural-network(2)/\n","\"\"\"\n","\n","\"\"\"\n","https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html\n","\"\"\"\n","\n","\n","from PIL import Image \n","import numpy as np \n","pre_img = Image.open(\"./broken_data/broken_data/broken_processed_data/20200519_12_broken_take14.jpg\")\n","#pre_img = Image.open(\"./normal_data/normal_processed_data/20200518_14_normal_take6.jpg\")\n","\n","pre_img = pre_img.convert('L')\n","      \n","# # 이미지를 28, 28로 일괄 리사이즈 \n","resized_pre_img = pre_img.resize((28,28))\n","np_pre_img = np.asarray(resized_pre_img)\n","np_pre_img = np.reshape(np_pre_img, [1,1,28,28])\n","#torch.Size([3056, 1, 28, 28])\n","#type(np_pre_img)\n","\n","pre_X = torch.from_numpy(np_pre_img).float()\n","#pre_X\n","#pre_X.shape\n","\n","result = torch.max(model(pre_X).data, 1)[1]\n","_pre_img = np.reshape(np_pre_img, [1,1,28,28])\n","#torch.Size([3056, 1, 28, 28])\n","#type(np_pre_img)\n","\n","pre_X = torch.from_numpy(np_pre_img).float()\n","#pre_X\n","#pre_X.shape\n","\n","result = torch.max(model(pre_X).data, 1)[1]\n","#print(result)\n","print(\"이 커피콩은 \",categories[result[0]], \"입니다.\")\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["이 커피콩은  broken 입니다.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jGo-d9HHw6vv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqEXBgi4w6vw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTAEptVKw6vy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvjNiSlcw6v0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkpjL6jZw6v2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfgF3Cwtw6v3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"abmUGuOGw6v6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nN9qrRFJw6v8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qtVgRkjZw6v9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lhFleIZ7w6v_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mikCJt9Iw6wC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"__KtBPfDw6wF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YaOXUvDcw6wH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_sQuNGcw6wK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EcyO0o3bw6wL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEjkpeRkw6wM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4BZFScWJw6wO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8n4O-OMw6wP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CGfyYKRmw6wQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}