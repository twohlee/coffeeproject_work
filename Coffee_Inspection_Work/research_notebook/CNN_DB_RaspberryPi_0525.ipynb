{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7-final"},"orig_nbformat":2,"kernelspec":{"name":"python37764bitprojectopencvconda6fc4edbc446e42ca82ff567e09c1586a","display_name":"Python 3.7.7 64-bit ('project_opencv': conda)"},"colab":{"name":"CNN_DB_RaspberryPi_0525.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"nijPiLTszWut","colab_type":"code","colab":{}},"source":["# groups_folder_path = '/content/drive/My Drive/beans'\n","# categories = [\"broken\", \"insect\", \"normal\"] # 해당 이미지들이 들어가 있는 폴더명 넣어주기 \n","# num_classes = len(categories)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnD7fgEZzWuw","colab_type":"code","colab":{},"outputId":"c7a7f41c-8e6d-468b-d550-c2493057b94e"},"source":["#pip install sklearn"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Collecting scikit-learn\n","  Downloading scikit_learn-0.23.0-cp37-cp37m-win_amd64.whl (6.8 MB)\n","Collecting joblib>=0.11\n","  Downloading joblib-0.15.1-py3-none-any.whl (298 kB)\n","Requirement already satisfied: scipy>=0.19.1 in c:\\users\\admin\\anaconda3\\envs\\project_opencv\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in c:\\users\\admin\\anaconda3\\envs\\project_opencv\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-2.0.0-py3-none-any.whl (34 kB)\n","Building wheels for collected packages: sklearn\n","  Building wheel for sklearn (setup.py): started\n","  Building wheel for sklearn (setup.py): finished with status 'done'\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1320 sha256=039a5a6d34665b365cd6d63473fee7a168aa3d9d3535ec647a162543acf0dc02\n","  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\46\\ef\\c3\\157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","Successfully built sklearn\n","Installing collected packages: joblib, threadpoolctl, scikit-learn, sklearn\n","Successfully installed joblib-0.15.1 scikit-learn-0.23.0 sklearn-0.0 threadpoolctl-2.0.0\n","Note: you may need to restart the kernel to use updated packages.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_GQr_ycMzWuz","colab_type":"code","colab":{}},"source":["import torch\n","from torch.autograd import Variable \n","import torch.nn as nn \n","import torch.nn.functional as F \n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import os \n","from PIL import Image \n","import numpy as np\n","import pandas as pd\n","from sklearn import datasets, model_selection"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qx3VC71LzWu1","colab_type":"code","colab":{}},"source":["import pymongo\n","import gridfs \n","from pymongo import MongoClient"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y49M-3ELzWu3","colab_type":"code","colab":{}},"source":["groups_folder_path = './beans'\n","categories = [\"broken\", \"normal\"] # 해당 이미지들이 들어가 있는 폴더명 넣어주기 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nz3xz4cOzWu5","colab_type":"code","colab":{}},"source":["# # mongodb에서 사진 불러오기 \n","# # category 나눠서 들어갈 수 있도록 하기 \n","\n","\n","\n","# if __name__ == '__main__' :\n","    \n","#     # connect to database \n","#     client = MongoClient('127.0.0.1', 27017)\n","\n","    \n","\n","\n","#     # read in the image \n","\n","#     for i,d in enumerate(categories):\n","#         files = os.listdir(groups_folder_path + '/'+ d)\n","#         database = client[d]\n","\n","#         # create a new gridfs object\n","#         fs = gridfs.GridFS(database)\n","\n","#         for f in files : \n","#             img = open(groups_folder_path + '/'+ d +'/' + f, 'rb')\n","#             thedata = img.read()\n","#             # store the data in the database. \n","#             # Returns the id of the file in gridFS \n","#             stored = fs.put(thedata, filename = f)\n","\n","    \n","    \n","    \n","\n","\n","\n","#     # retrieve what was just stored \n","#     #outputdata = fs.get(stored).read()\n","\n","#     # create an output file and store the image in the output file \n","#     # outfilename = './OpenCV/data/20200508_test1_sample1.jpg'\n","#     # output = open(outfilename, 'wb')\n","#     # output.write(outputdata)\n","#     # # close the output file \n","#     # output.close()\n","\n","#     # for experimental code restore to known state and close connection \n","\n","#     #fs.delete(stored)\n","#     #client.drop_database('example')\n","#     client.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FaPqUtU4zWu8","colab_type":"code","colab":{},"outputId":"34369ba9-1c42-4d4e-b7cd-093c98f02101"},"source":["# pip install StringIO"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n","ERROR: Could not find a version that satisfies the requirement StringIO (from versions: none)\n","ERROR: No matching distribution found for StringIO\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aufDdD6pzWu_","colab_type":"code","colab":{}},"source":["# import base64\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jfyfqJOizWvC","colab_type":"code","colab":{},"outputId":"65bce960-4162-43b8-a57f-1ec830bdc755"},"source":["# img = Image.open(\"./normal_data/normal_align_test_image/20200518_test_inadvance1_off.jpeg\")\n","# img.size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2160, 2160)"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"qdr67x2vzWvE","colab_type":"code","colab":{}},"source":["import io"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":["outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend"],"id":"CF-5PxMxzWvG","colab_type":"code","colab":{},"outputId":"4c583d2c-3599-43ad-fd72-000d60687417"},"source":["data = []\n","label = []\n","\n","# groups_folder_path = './normal_data'\n","# categories = [\"normal_align_test_image\", \"normal_processed_data\", \"normal_raw_data\" ] # 해당 이미지들이 들어가 있는 폴더명 넣어주기 \n","\n","if __name__ == '__main__' :  \n","  client = MongoClient('127.0.0.1', 27017)\n","  # read in the image \n","  for i,d in enumerate(categories):\n","    database  = client[d]\n","    files     = os.listdir(groups_folder_path + '/'+ d)\n","    \n","    # create a new gridfs object\n","    fs        = gridfs.GridFS(database)\n","\n","    #print( '->' +  d )\n","    for f in files : \n","      #print( groups_folder_path + '/'+ d +'/' + f )\n","      fp         = open(groups_folder_path + '/'+ d +'/' + f, 'rb')\n","      # bytes로 읽는다\n","      thedata     = fp.read()            \n","      \n","      image = Image.open(io.BytesIO(thedata))\n","      #image.show()\n","      \n","      \n","      \n","      #print( type(thedata), len(thedata) )\n","      # 디비에 저장\n","      stored      = fs.put(thedata, filename = f)      \n","      # 디비에서 다시 읽는다\n","      outputdata  = fs.get(stored).read()\n","      #print( type(outputdata), len(outputdata) )\n","      #print( '-'*10 )\n","      \n","      thedata2 = Image.open(fp, mode='r')\n","      \n","\n","      #thedata2 = Image.frombytes('RGB', (2160,2160), outputdata, 'raw')      \n","      # #thedata = Image.open(StringIO.StringIO(outputdata))\n","      # # 이미지 흑백으로 변경 \n","      img = thedata2.convert('L')\n","      # # 이미지를 28, 28로 일괄 리사이즈 \n","      resize_img = img.resize((28,28))\n","      black_resize_img = np.asarray(resize_img)\n","      # # 가공한 이미지 추가 \n","      data.append(black_resize_img)\n","      # # label : broken, insect, normal\n","      label.append(i)\n","\n","      fp.close()\n","      #break\n","\n","\n","  client.close()\n","\n","pd.DataFrame(data[0][0]).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 1)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"pRvTA3O1zWvI","colab_type":"code","colab":{}},"source":["data = np.array(data, dtype = 'float32')\n","label = np.array(label, dtype = 'int64')\n","\n","train_X, test_X, train_Y, test_Y = model_selection.train_test_split(data, label, test_size = 0.1)\n","\n","train_X = torch.from_numpy(train_X).float()\n","train_Y = torch.from_numpy(train_Y).long()\n","\n","test_X = torch.from_numpy(test_X).float()\n","test_Y = torch.from_numpy(test_Y).long()\n","\n","#train = TensorDataset(train_X, train_Y)\n","#train_loader = DataLoader(train, batch_size = 32, shuffle = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuvF2mXRzWvK","colab_type":"code","colab":{},"outputId":"14ffff73-b660-423a-a05b-6707f29157c0"},"source":["train_X"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n","\n","        ...,\n","\n","        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 3.,  4.,  5.,  ...,  0.,  0.,  0.],\n","         [ 5.,  4., 24.,  ...,  0.,  0.,  0.],\n","         [ 6.,  0., 64.,  ...,  0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n","\n","        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         ...,\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"6QI9w_PIzWvM","colab_type":"code","colab":{},"outputId":"9bea4491-764e-49b3-9cd0-0954e72ef23e"},"source":["train_Y"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 0,  ..., 0, 1, 1])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"gbR3ZLCczWvO","colab_type":"code","colab":{},"outputId":"f5c0a478-8035-4c27-fc6c-5904ffe7dceb"},"source":["test_X"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        ...,\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 1., 1., 1.],\n","         [0., 0., 0.,  ..., 1., 1., 1.],\n","         [0., 0., 0.,  ..., 1., 1., 1.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"tNl9cNeuzWvQ","colab_type":"code","colab":{},"outputId":"4976f84b-42d7-4eb0-8653-8d3a0470bda8"},"source":["test_Y"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n","        1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n","        0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n","        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n","        1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n","        0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n","        1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n","        0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n","        0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n","        1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n","        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n","        1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"qm7FRrjszWvT","colab_type":"code","colab":{},"outputId":"f83823b3-97ed-42b7-9e4f-f2b974e70131"},"source":["train_X.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3049, 28, 28])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kboX7knPzWvV","colab_type":"code","colab":{},"outputId":"60394a7c-51a3-47d2-ee85-f8d6fc5d0322"},"source":["train_Y.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3049])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"DmN5tclwzWvX","colab_type":"code","colab":{},"outputId":"0b519c89-afac-49e2-b4d2-75fd46a82a12"},"source":["test_X.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([339, 28, 28])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"qu3FOpa2zWvZ","colab_type":"code","colab":{},"outputId":"c08c345b-f97b-4d33-fb99-f049734dc364"},"source":["test_Y.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([339])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"_V-7pJhSzWvb","colab_type":"code","colab":{}},"source":["# 데이터 차원 맞추기\n","train_X = train_X.unsqueeze(1)\n","test_X = test_X.unsqueeze(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gd0aiWxizWvd","colab_type":"code","colab":{},"outputId":"0fdc0d0e-4d3c-4558-926c-c9cc8c543901"},"source":["train_X.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3049, 1, 28, 28])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"qkjgC9-NzWvf","colab_type":"code","colab":{},"outputId":"91146f87-db1d-43c1-866b-556412817812"},"source":["test_X.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([339, 1, 28, 28])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"b5dUaGpBzWvh","colab_type":"code","colab":{}},"source":["# 만약 GPU를 사용 가능하다면 device 값이 cuda가 되고, 아니라면 cpu가 됩니다.\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# 랜덤 시드 고정\n","torch.manual_seed(777)\n","\n","# GPU 사용 가능일 경우 랜덤 시드 고정\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Z9HpIOazWvj","colab_type":"code","colab":{},"outputId":"108c4f37-b7c5-4085-bb02-6d3d5f0577e6"},"source":["dataset = TensorDataset(train_X, train_Y)\n","type(dataset)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.utils.data.dataset.TensorDataset"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"L0t2C_G3zWvl","colab_type":"code","colab":{}},"source":["learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 100\n","\n","data_loader = torch.utils.data.DataLoader(dataset=dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=True,\n","                                          drop_last=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mn5OLIrzWvn","colab_type":"code","colab":{}},"source":["class CNN(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        # 첫번째층\n","        # ImgIn shape=(?, 28, 28, 1)\n","        #    Conv     -> (?, 28, 28, 32)\n","        #    Pool     -> (?, 14, 14, 32)\n","        self.layer1 = torch.nn.Sequential(\n","            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1 ),\n","            torch.nn.Tanh(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # 두번째층\n","        # ImgIn shape=(?, 14, 14, 32)\n","        #    Conv      ->(?, 14, 14, 64)\n","        #    Pool      ->(?, 7, 7, 64)\n","        self.layer2 = torch.nn.Sequential(\n","            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            torch.nn.Tanh(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # 전결합층 7x7x64 inputs -> 10 outputs\n","        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n","\n","        # 전결합층 한정으로 가중치 초기화\n","        torch.nn.init.xavier_uniform_(self.fc.weight)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n","        out = self.fc(out)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"65qm8KybzWvp","colab_type":"code","colab":{},"outputId":"467639f7-3cb0-49dc-9a72-7aeae42fc71e"},"source":["# 모델을 정의합니다.\n","\n","# CNN 모델 정의\n","model = CNN().to(device)\n","# 비용 함수와 옵티마이저를 정의합니다.\n","\n","criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","# 총 배치의 수를 출력해보겠습니다.\n","\n","total_batch = len(data_loader)\n","print('총 배치의 수 : {}'.format(total_batch))\n","# 총 배치의 수 : 600\n","# 총 배치의 수는 600입니다. 그런데 배치 크기를 100으로 했으므로 결국 훈련 데이터는 총 60,000개란 의미입니다. 이제 모델을 훈련시켜보겠습니다. (시간이 꽤 오래 걸립니다.)\n","\n","model.train()\n","\n","for epoch in range(training_epochs):\n","    \n","    avg_cost = 0\n","    \n","    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n","        # image is already size of (28x28), no reshape\n","        # label is not one-hot encoded\n","        X = X.to(device)\n","        Y = Y.to(device)\n","\n","        optimizer.zero_grad()\n","        hypothesis = model(X)\n","        cost = criterion(hypothesis, Y)\n","        cost.backward()\n","        optimizer.step()\n","\n","        avg_cost += cost / total_batch\n","\n","    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["총 배치의 수 : 30\n","[Epoch:    1] cost = 0.718078971\n","[Epoch:    2] cost = 0.469824076\n","[Epoch:    3] cost = 0.37024644\n","[Epoch:    4] cost = 0.318217337\n","[Epoch:    5] cost = 0.27054131\n","[Epoch:    6] cost = 0.255614221\n","[Epoch:    7] cost = 0.21690461\n","[Epoch:    8] cost = 0.256442755\n","[Epoch:    9] cost = 0.206047744\n","[Epoch:   10] cost = 0.172464445\n","[Epoch:   11] cost = 0.152665615\n","[Epoch:   12] cost = 0.156579867\n","[Epoch:   13] cost = 0.137855798\n","[Epoch:   14] cost = 0.127083644\n","[Epoch:   15] cost = 0.116798639\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GGjb8-vWzWvr","colab_type":"code","colab":{},"outputId":"df0975ca-4152-4509-c078-b9bc7d69942e"},"source":["# test dataset 만들기 \n","testset = TensorDataset(test_X, test_Y)\n","type(testset)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.utils.data.dataset.TensorDataset"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"nX2hd2tLzWvs","colab_type":"code","colab":{}},"source":["batch_size = 100\n","\n","testloader = torch.utils.data.DataLoader(dataset=testset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          drop_last=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hRyh8ugyzWvu","colab_type":"code","colab":{},"outputId":"fc22f91e-08d0-4274-c182-46729b01a6ee"},"source":["# 테스트 데이터로 모델 테스트 진행 \n","\"\"\"\n","https://wingnim.tistory.com/36\n","\"\"\"\n","\n","model.eval()\n","test_loss = 0 \n","correct = 0\n","\n","for data, target in testloader: \n","    data = data.to(device)\n","    target = target.to(device) \n","\n","    output = model(data)\n","\n","    # sum up batch loss \n","    test_loss += criterion(output, target).data\n","\n","    # get the index of the max log-probability \n","    pred = output.data.max(1, keepdim = True)[1]\n","    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","\n","test_loss /= len(testloader.dataset)/batch_size\n","\n","print('\\nTest set : Average loss : {: .4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Test set : Average loss :  0.1505, Accuracy: 279/339 (82%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OvQ-Y7HRzWvx","colab_type":"code","colab":{}},"source":["\"\"\"\n","https://medium.com/@trilliwon/pytorch-%E1%84%8B%E1%85%B5%E1%84%86%E1%85%B5%E1%84%8C%E1%85%B5-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2-%E1%84%92%E1%85%A2%E1%84%87%E1%85%A9%E1%84%80%E1%85%B5-4ceab523cb66\n","\"\"\"\n","\n","# # 테스트 데이터로 테스트 진행 \n","\n","# categories = [\"broken\", \"normal\"]\n","\n","# class_correct = list(0. for i in range(2))\n","# class_total = list(0. for i in range(2))\n","\n","# with torch.no_grad():\n","#     for data in testloader:\n","#         images, labels = data \n","#         outputs = net(images)\n","#         _, predicted = torch.max(outputs, 1) \n","#         c = (predicted == labels).squeeze()\n","#         for i in range(4):\n","#              label = labels[i]\n","#              class_correct[label] += c[i].item()\n","#              class_total[label] += 1\n","# for i in range(10):\n","#     print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i]/class_total[i]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SSxQTHhpzWvz","colab_type":"code","colab":{}},"source":["# 라즈베리파이에서 찍은 사진 \n","# 공유 폴더 이용해서 파일 불러오기 \n","# 파일 불러와서 구축된 CNN 모델에 대입하여 예측 결과 확인하기 \n","\n","import os \n","#os.path.join('Z:', '0525.jpg')\n","pre_img = Image.open('Z:\\\\normal_test.jpg')\n","#pre_img = pre_img.read()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzHvEFCKzWv1","colab_type":"code","colab":{},"outputId":"eb65980d-fb4a-4434-bfe1-756e1f4b572d"},"source":["# CNN 모델에 이미지 대입하여 예측결과 확인하기 \n","# 참고 사이트 \n","\n","\"\"\"\n","https://github.com/MLlounge/ML-Project/blob/master/Basic%20Project/CNN%20-%20Distinguish%20language%20according%20to%20characters/CNN%20-%20Distinguish%20language%20according%20to%20characters.py\n","\"\"\"\n","\n","\"\"\"\n","https://www.yceffort.kr/2019/01/30/pytorch-3-convolutional-neural-network(2)/\n","\"\"\"\n","\n","\"\"\"\n","https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html\n","\"\"\"\n","\n","\n","from PIL import Image \n","import numpy as np \n","#pre_img = Image.open(\"./broken_data/broken_data/broken_processed_data/20200519_12_broken_take14.jpg\")\n","#pre_img = Image.open(\"./normal_data/normal_processed_data/20200518_14_normal_take6.jpg\")\n","\n","pre_img = pre_img.convert('L')\n","      \n","# # 이미지를 28, 28로 일괄 리사이즈 \n","resized_pre_img = pre_img.resize((28,28))\n","np_pre_img = np.asarray(resized_pre_img)\n","np_pre_img = np.reshape(np_pre_img, [1,1,28,28])\n","#torch.Size([3056, 1, 28, 28])\n","#type(np_pre_img)\n","\n","pre_X = torch.from_numpy(np_pre_img).float()\n","#pre_X\n","#pre_X.shape\n","\n","result = torch.max(model(pre_X).data, 1)[1]\n","_pre_img = np.reshape(np_pre_img, [1,1,28,28])\n","#torch.Size([3056, 1, 28, 28])\n","#type(np_pre_img)\n","\n","pre_X = torch.from_numpy(np_pre_img).float()\n","#pre_X\n","#pre_X.shape\n","\n","result = torch.max(model(pre_X).data, 1)[1]\n","#print(result)\n","print(\"이 커피콩은 \",categories[result[0]], \"입니다.\")\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["이 커피콩은  normal 입니다.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bmCCKwQuzWv2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SZfKBkoezWv4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1pwAYAQNzWv5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0fIzlPnzWv7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2shMgJ2zWv9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CBdTSeBhzWv-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhXsGzIuzWwA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuXVEPIAzWwD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Pg9fhwCzWwF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XGXGT9zozWwH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mdCmQGxzWwJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MqcPz2KZzWwL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tawxpc2JzWwN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlYs7n2gzWwP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NvfUnMrmzWwQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IhIpvqAfzWwS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mc1-pBILzWwT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PlmE3HI2zWwV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLRu9tsXzWwY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}